{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "import datetime\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#set up database connection\n",
    "uri = f\"\"\"mongodb+srv://{os.getenv(\"MONGODB_USERNAME\")}:{os.getenv(\"MONGODB_PASSWORD\")}@airatyai.mrtegvw.mongodb.net/?retryWrites=true&w=majority\"\"\"\n",
    "mongodb_client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "db = mongodb_client.smart_conversation\n",
    "try:\n",
    "    mongodb_client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "#set up llm\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertOneResult(ObjectId('658b36bbb653b5647be00d66'), acknowledged=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uploading the summary as a standalone document to MongoDB\n",
    "collection = db.zoom_transcript\n",
    "model = \"text-embedding-ada-002\"\n",
    "def generate_embedding(text: str) -> list[float]:\n",
    "\tresponse = client.embeddings.create(\n",
    "\t\tinput=text, \n",
    "\t\tmodel=model,\n",
    "\t\tencoding_format=\"float\")\n",
    "\treturn response.data[0].embedding\n",
    "summary= '''\n",
    "This is the summary or key takeaways from the meeting:\n",
    "The meeting focused on discussing a proposed '10%' increase in service prices, considering client feedback and market positioning.\n",
    "Jane (CEO) highlighted rising operational costs, while David (VP of Business Development) and Thanh (VP of Marketing) expressed concerns over client pushback and market perception.\n",
    "Thanh proposed introducing new features, like an advanced analytics dashboard and personalized marketing consultation sessions, to justify the price increase.\n",
    "The team considered a tiered price increase strategy, rewarding loyalty of existing clients while aligning with business sustainability goals. They agreed to develop a phased implementation and communication plan before the next meeting.\n",
    "'''\n",
    "collection.insert_one({\"application\": \"smart_conversation\",\n",
    "\t\t\t\t\t   \"document_source\": \"zoom_transcript\",\n",
    "\t\t\t\t\t   \"context\": summary, \n",
    "\t\t\t\t\t   \"embedding_ada002\": generate_embedding(summary),\n",
    "\t\t\t\t\t   \"created_at\": datetime.datetime.now(tz=datetime.timezone.utc)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting chunks of the transcript into separate documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader(\"transcript.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "# len(docs)\n",
    "# print(docs[1].page_content)\n",
    "for doc in docs:\n",
    "    collection.insert_one({\"application\": \"smart_conversation\",\n",
    "\t\t\t\t\t   \"document_source\": \"zoom_transcript\",\n",
    "\t\t\t\t\t   \"context\": doc.page_content, \n",
    "\t\t\t\t\t   \"embedding_ada002\": generate_embedding(doc.page_content),\n",
    "\t\t\t\t\t   \"created_at\": datetime.datetime.now(tz=datetime.timezone.utc)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:05] Thanh: I agree with David's concerns. Our brand image is tied to affordability and value. A sudden 10% increase might disrupt our market perception. We need a strategic approach if we decide to go this route.\n",
      "[00:01:20] Jane: I hear your concerns. However, our operating costs have been rising steadily, and we haven't adjusted our prices in over two years. It's crucial for our sustainability. How can we mitigate the risks you both mentioned?\n",
      "[00:01:35] David: One approach could be to gradually implement the increase, starting with our premium services. This way, we can test the waters without alarming our entire client base.\n",
      "\n",
      "[00:03:45] David: Now, on the topic of the price increase, I've been crunching numbers, and I feel a 3% increase is more in line with our current market position. A 10% hike seems excessive and might cause significant client churn.\n",
      "[00:03:55] Thanh: David, I see your point, but a 3% increase won't cover our rising operational costs. We need to think long-term. A 10% increase, coupled with a strong communication strategy, can position us as a premium service provider without alienating our client base.\n",
      "[00:04:05] Jane: Both of you raise valid points. David, while I understand the caution behind a 3% increase, it might not be sufficient. Thanh, we also need to consider the risk of a higher increase. We can't afford to lose our loyal clients. We need a middle ground.\n",
      "\n",
      "[00:00:05] Jane: Good morning, everyone! Hope you're all doing well. How's the weather in your areas?\n",
      "[00:00:15] David: Morning, Jane. It's pretty sunny here. Perfect for a weekend hike!\n",
      "[00:00:20] Thanh: Hi all, it's been raining non-stop here. Perfect for staying in and reading.\n",
      "[00:00:30] Jane: That sounds lovely, Thanh. Alright, let's dive into today's agenda. We need to discuss the potential 10% increase in our service prices. David, can you start us off with your thoughts?\n",
      "[00:00:45] David: Certainly, Jane. I've been analyzing our current market position and client feedback. While I understand the need for a price increase, I'm concerned about the potential client pushback. Our competitive edge has always been high-quality service at a reasonable price.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RAG answer\n",
    "#retrieving from MongoDB\n",
    "question = \"what did Thanh and David think about the price increase?\"\n",
    "results = collection.aggregate([\n",
    "  {\"$vectorSearch\": {\n",
    "    \"index\": \"smartConverIndex\",\n",
    "    \"queryVector\": generate_embedding(question),\n",
    "    \"path\": \"embedding_ada002\",\n",
    "    \"numCandidates\": 14,\n",
    "    \"limit\": 3,\n",
    "      }},\n",
    "      {\n",
    "    '$project': {\n",
    "      '_id': 1, \n",
    "      'context': 1,  \n",
    "      'score': {\n",
    "        '$meta': 'vectorSearchScore'\n",
    "      }\n",
    "    }}\n",
    "])\n",
    "relevant_text= \"\"\n",
    "for i in results:\n",
    "    relevant_text += f\"\"\"{i[\"context\"]}\\n\\n\"\"\"\n",
    "\n",
    "print(relevant_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanh expressed concern about a sudden 10% increase, as it could disrupt the brand's affordability and value perception. David suggested a gradual implementation starting with premium services to test the waters without alarming the entire client base.\n",
      "prompt tokens:  659\n",
      "total tokens:  703\n"
     ]
    }
   ],
   "source": [
    "#retrieve relevant documents from MongoDB\n",
    "prompt = f\"\"\"My name is John, who is the head of product. I missed the meeting. The relevant portion of the meeting transcript and the question, which are delimitted by the tripple backtics, are as follows:\n",
    "```{relevant_text}```\n",
    "This is the question:\n",
    "```{question}```\n",
    "Your answer is\n",
    "\"\"\"\n",
    "\n",
    "def openai_answer(prompt):\n",
    "    stream = client.chat.completions.create(\n",
    "        # model=\"gpt-4-1106-preview\",\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are the executive assistant. You help answer any questions people have regarding the meeting transcript. Your answer should be concise and each answer must be fewer than 140 tokens. You are not allowed to answer any questions outside of the meeting transcript.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "        # stream=True,\n",
    "    )\n",
    "    # for chunk in stream:\n",
    "    #     print(chunk.choices[0].delta.content)\n",
    "    print(stream.choices[0].message.content)\n",
    "    print(\"prompt tokens: \", stream.usage.prompt_tokens)\n",
    "    print(\"answer tokens: \", stream.usage.completion_tokens)\n",
    "    print(\"total tokens: \", stream.usage.total_tokens)  \n",
    "openai_answer(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
