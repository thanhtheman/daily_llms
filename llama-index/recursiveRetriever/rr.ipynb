{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot \n",
    "# pip install camelot-py[cv], then install ghostscript by using conda, then pip install ghostscript for the python wrapper\n",
    "from llama_index import Document, SummaryIndex\n",
    "from llama_index import VectorStoreIndex, ServiceContext, LLMPredictor\n",
    "from llama_index.retrievers import RecursiveRetriever\n",
    "from llama_index.query_engine import PandasQueryEngine, RetrieverQueryEngine\n",
    "from llama_index.schema import IndexNode\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index import download_loader\n",
    "from pathlib import Path\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Just don't use llama-hub, use download_loader instead\"\"\"\n",
    "file_path = \"./the_world_billionaires.pdf\"\n",
    "reader = download_loader(\"PyMuPDFReader\")\n",
    "loader = reader()\n",
    "docs = loader.load_data(file_path=Path(file_path), metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables(path: str, pages: List[int]):\n",
    "    table_dfs = []\n",
    "    for page in pages:\n",
    "        table_list = camelot.read_pdf(path, pages=str(page))\n",
    "        table_df = table_list[0].df\n",
    "        table_df = (\n",
    "            table_df.rename(columns=table_df.iloc[0])\n",
    "            .drop(table_df.index[0])\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        table_dfs.append(table_df)\n",
    "    return table_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dfs = get_tables(file_path, pages=[3, 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we create each query engine for each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.8)\n",
    "service_context = ServiceContext.from_defaults(llm=llm)\n",
    "df_query_engines = [PandasQueryEngine(table_df, service_context=service_context) for table_df in table_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793\n"
     ]
    }
   ],
   "source": [
    "response = df_query_engines[1].query(\"How many billionaires were there in 2009?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_nodes = service_context.node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the df_nodes is just a tuple with the description of the table(summary) and its index\n",
    "After that, we want to map the df nodes to the list of df query engines created in the previous step.\n",
    "the df node and the df engine is linked through the idx variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = [\n",
    "    (\n",
    "        \"this node provides information about the world's richest billionaires in 2023\"\n",
    "    ),\n",
    "    (\n",
    "        \"this node provides information on the numbner of billionaires and their combined networth from 2000 to 2023\"\n",
    "    )\n",
    "]\n",
    "\n",
    "df_nodes = [IndexNode(text=summary, index_id=f\"pandas{idx}\")\n",
    "            for idx, summary in enumerate(summaries)]\n",
    "\n",
    "df_id_query_engine_mapping = {\n",
    "    f\"pandas{idx}\": df_query_engine for idx, df_query_engine in enumerate(df_query_engines)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = [\n",
    "    (\n",
    "        \"This node provides information about the world's richest billionaires\"\n",
    "        \" in 2023\"\n",
    "    ),\n",
    "    (\n",
    "        \"This node provides information on the number of billionaires and\"\n",
    "        \" their combined net worth from 2000 to 2023.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "df_nodes = [\n",
    "    IndexNode(text=summary, index_id=f\"pandas{idx}\")\n",
    "    for idx, summary in enumerate(summaries)\n",
    "]\n",
    "\n",
    "df_id_query_engine_mapping = {\n",
    "    f\"pandas{idx}\": df_query_engine\n",
    "    for idx, df_query_engine in enumerate(df_query_engines)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indexing our database, with all the texts plus the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type PosixPath is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/thanhquach/projects/llms/llama-index/recursiveRetriever/rr.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/thanhquach/projects/llms/llama-index/recursiveRetriever/rr.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vector_index \u001b[39m=\u001b[39m VectorStoreIndex(doc_nodes \u001b[39m+\u001b[39;49m df_nodes)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thanhquach/projects/llms/llama-index/recursiveRetriever/rr.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m vector_retriever \u001b[39m=\u001b[39m vector_index\u001b[39m.\u001b[39mas_retriever(similarity_top_k\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llms/lib/python3.11/site-packages/llama_index/indices/vector_store/base.py:49\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[0;34m(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_async \u001b[39m=\u001b[39m use_async\n\u001b[1;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override \u001b[39m=\u001b[39m store_nodes_override\n\u001b[0;32m---> 49\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     50\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[1;32m     51\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[1;32m     52\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[1;32m     53\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[1;32m     54\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[1;32m     55\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     56\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llms/lib/python3.11/site-packages/llama_index/indices/base.py:71\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[0;34m(self, nodes, index_struct, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m index_struct \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[39massert\u001b[39;00m nodes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     index_struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index_from_nodes(nodes)\n\u001b[1;32m     72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct \u001b[39m=\u001b[39m index_struct\n\u001b[1;32m     73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_storage_context\u001b[39m.\u001b[39mindex_store\u001b[39m.\u001b[39madd_index_struct(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llms/lib/python3.11/site-packages/llama_index/indices/vector_store/base.py:238\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_index_from_nodes\u001b[39m(\u001b[39mself\u001b[39m, nodes: Sequence[BaseNode]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m IndexDict:\n\u001b[1;32m    232\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build the index from nodes.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \n\u001b[1;32m    234\u001b[0m \u001b[39m    NOTE: Overrides BaseIndex.build_index_from_nodes.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m        VectorStoreIndex only stores nodes in document store\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39m        if vector store does not store text\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_index_from_nodes(nodes)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llms/lib/python3.11/site-packages/llama_index/indices/vector_store/base.py:226\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    224\u001b[0m     run_async_tasks(tasks)\n\u001b[1;32m    225\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_nodes_to_index(\n\u001b[1;32m    227\u001b[0m         index_struct, nodes, show_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_show_progress\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    229\u001b[0m \u001b[39mreturn\u001b[39;00m index_struct\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llms/lib/python3.11/site-packages/llama_index/indices/vector_store/base.py:187\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[0;34m(self, index_struct, nodes, show_progress)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    186\u001b[0m nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_node_with_embedding(nodes, show_progress)\n\u001b[0;32m--> 187\u001b[0m new_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vector_store\u001b[39m.\u001b[39;49madd(nodes)\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mstores_text \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override:\n\u001b[1;32m    190\u001b[0m     \u001b[39m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     \u001b[39m# we need to add the nodes to the index struct and document store\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     \u001b[39mfor\u001b[39;00m node, new_id \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(nodes, new_ids):\n\u001b[1;32m    193\u001b[0m         \u001b[39m# NOTE: remove embedding from node to avoid duplication\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llms/lib/python3.11/site-packages/llama_index/vector_stores/simple.py:137\u001b[0m, in \u001b[0;36mSimpleVectorStore.add\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39membedding_dict[node\u001b[39m.\u001b[39mnode_id] \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mget_embedding()\n\u001b[1;32m    135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39mtext_id_to_ref_doc_id[node\u001b[39m.\u001b[39mnode_id] \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mref_doc_id \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 137\u001b[0m metadata \u001b[39m=\u001b[39m node_to_metadata_dict(\n\u001b[1;32m    138\u001b[0m     node, remove_text\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, flat_metadata\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    139\u001b[0m )\n\u001b[1;32m    140\u001b[0m metadata\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39m_node_content\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    141\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39mmetadata_dict[node\u001b[39m.\u001b[39mnode_id] \u001b[39m=\u001b[39m metadata\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llms/lib/python3.11/site-packages/llama_index/vector_stores/utils.py:46\u001b[0m, in \u001b[0;36mnode_to_metadata_dict\u001b[0;34m(node, remove_text, text_field, flat_metadata)\u001b[0m\n\u001b[1;32m     43\u001b[0m node_dict[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m# dump remainder of node_dict to json string\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m metadata[\u001b[39m\"\u001b[39m\u001b[39m_node_content\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mdumps(node_dict)\n\u001b[1;32m     48\u001b[0m \u001b[39m# store ref doc id at top level to allow metadata filtering\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m# kept for backwards compatibility, will consolidate in future\u001b[39;00m\n\u001b[1;32m     50\u001b[0m metadata[\u001b[39m\"\u001b[39m\u001b[39mdocument_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mref_doc_id \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# for Chroma\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llms/lib/python3.11/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m skipkeys \u001b[39mand\u001b[39;00m ensure_ascii \u001b[39mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[39mand\u001b[39;00m allow_nan \u001b[39mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m indent \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m separators \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sort_keys \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_encoder\u001b[39m.\u001b[39;49mencode(obj)\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llms/lib/python3.11/json/encoder.py:200\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[39mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    197\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterencode(o, _one_shot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    202\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llms/lib/python3.11/json/encoder.py:258\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[1;32m    255\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[1;32m    256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[1;32m    257\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 258\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/llms/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type PosixPath is not JSON serializable"
     ]
    }
   ],
   "source": [
    "vector_index = VectorStoreIndex(doc_nodes + df_nodes)\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
